\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Acknowledgments}{ii}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{iv}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Table of Contents}{v}{section*.3}\protected@file@percent }
\citation{fig:neuron_model}
\citation{fig:sigmoid}
\citation{fig:neural_network_model}
\citation{fig:mnist}
\citation{fig:mnist_incorrect}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{vii}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Neural networks: introduction}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project goal}{1}{section.1.2}\protected@file@percent }
\citation{neural-network-intro}
\citation{neural-network-history}
\citation{neural-network-intro-book}
\citation{fig:neuron_model}
\citation{fig:neuron_model}
\citation{fig:sigmoid}
\citation{fig:sigmoid}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background and Related Work}{2}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:LitReview}{{2}{2}{Background and Related Work}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neural networks: explanation}{2}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Neuron model\cite  {fig:neuron_model}.\relax }}{2}{figure.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:neuron_model}{{2.1}{2}{Neuron model\cite {fig:neuron_model}.\relax }{figure.caption.7}{}}
\citation{fig:neural_network_model}
\citation{fig:neural_network_model}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Sigmoid graph\cite  {fig:sigmoid}.\relax }}{3}{figure.caption.8}\protected@file@percent }
\newlabel{fig:sigmoid}{{2.2}{3}{Sigmoid graph\cite {fig:sigmoid}.\relax }{figure.caption.8}{}}
\citation{nielsen}
\citation{towards-data-science}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Dense layer neural network model\cite  {fig:neural_network_model}.\relax }}{4}{figure.caption.9}\protected@file@percent }
\newlabel{fig:neural_network_model}{{2.3}{4}{Dense layer neural network model\cite {fig:neural_network_model}.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Training}{4}{subsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Stochastic gradient example. Y-Axis represents accuracy rate\relax }}{5}{figure.caption.10}\protected@file@percent }
\newlabel{fig:gradient}{{2.4}{5}{Stochastic gradient example. Y-Axis represents accuracy rate\relax }{figure.caption.10}{}}
\citation{underfitting-machine-learning}
\citation{model-complexity}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Global maxima example. Y-Axis represents accuracy rate\relax }}{6}{figure.caption.11}\protected@file@percent }
\newlabel{fig:global_minima}{{2.5}{6}{Global maxima example. Y-Axis represents accuracy rate\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Complexities of neural networks}{6}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Overfitting and underfitting}{6}{subsection.2.2.1}\protected@file@percent }
\citation{backprop-time-complexity}
\citation{research-1}
\citation{research-2}
\citation{research-3}
\citation{molchanov2019taylor}
\citation{8119196}
\citation{7093194}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Complexities}{7}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Research into neural network complexity}{7}{section.2.3}\protected@file@percent }
\citation{stochastic-numbers}
\citation{stochastic-computing-systems}
\citation{stochastic-cnn}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Research plan}{8}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Stochastic computing}{8}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Advantages of stochastic numbers}{8}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Disadvantages of stochastic numbers}{8}{subsection.3.1.2}\protected@file@percent }
\citation{tensorflow}
\citation{lecun-website}
\citation{fig:mnist}
\citation{fig:mnist}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Reasoning behind stochastic numbers}{9}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Approach}{9}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Tensorflow}{9}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}MNIST dataset}{9}{subsection.3.2.2}\protected@file@percent }
\citation{lecun-98}
\citation{lecun-98}
\citation{fig:mnist_incorrect}
\citation{fig:mnist_incorrect}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Samples of the MNIST dataset\cite  {fig:mnist}.\relax }}{10}{figure.caption.12}\protected@file@percent }
\newlabel{fig:mnist}{{3.1}{10}{Samples of the MNIST dataset\cite {fig:mnist}.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Samples of ambiguous digits\cite  {fig:mnist_incorrect}.\relax }}{10}{figure.caption.13}\protected@file@percent }
\newlabel{fig:incorrect_mnist}{{3.2}{10}{Samples of ambiguous digits\cite {fig:mnist_incorrect}.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Neural network model}{11}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Project plan}{12}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Setup}{12}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Baselines}{12}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Stochastic model}{13}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Compilation}{13}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Preliminary results}{14}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Stochastic numbers}{14}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Stochastic numbers: Abstract}{14}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Bit size}{15}{subsection.5.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Bit size results.\relax }}{15}{figure.caption.14}\protected@file@percent }
\newlabel{fig:bitsize}{{5.1}{15}{Bit size results.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Noise tests}{15}{subsection.5.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Noise test results.\relax }}{16}{figure.caption.15}\protected@file@percent }
\newlabel{fig:noise}{{5.2}{16}{Noise test results.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Left is original, right is inverted stochastic layer result.\relax }}{16}{figure.caption.16}\protected@file@percent }
\newlabel{fig:noise_stochastic_inverted}{{5.3}{16}{Left is original, right is inverted stochastic layer result.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Left is original, right is corrected stochastic layer result.\relax }}{17}{figure.caption.17}\protected@file@percent }
\newlabel{fig:noise_stochastic}{{5.4}{17}{Left is original, right is corrected stochastic layer result.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Corrected noise test results.\relax }}{17}{figure.caption.18}\protected@file@percent }
\newlabel{fig:noise_corrected}{{5.5}{17}{Corrected noise test results.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Inverted noise test results.\relax }}{18}{figure.caption.19}\protected@file@percent }
\newlabel{fig:noise_normal_inverted}{{5.6}{18}{Inverted noise test results.\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}Noise shuffle}{19}{subsection.5.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Noise shuffle results.\relax }}{19}{figure.caption.20}\protected@file@percent }
\newlabel{fig:noise_shuffle}{{5.7}{19}{Noise shuffle results.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Reduced dataset}{20}{subsection.5.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Bit size results.\relax }}{20}{figure.caption.21}\protected@file@percent }
\newlabel{fig:dataset}{{5.8}{20}{Bit size results.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.6}Reduced Epochs}{21}{subsection.5.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Epoch results.\relax }}{21}{figure.caption.22}\protected@file@percent }
\newlabel{fig:epoch}{{5.9}{21}{Epoch results.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.7}Convolution2D}{21}{subsection.5.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Conv2D results.\relax }}{22}{figure.caption.23}\protected@file@percent }
\newlabel{fig:conv2d}{{5.10}{22}{Conv2D results.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.8}Dense layer size}{23}{subsection.5.1.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Dense layer results.\relax }}{23}{figure.caption.24}\protected@file@percent }
\newlabel{fig:denselayer}{{5.11}{23}{Dense layer results.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions and Future Work}{24}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Conclusions}{{6}{24}{Conclusions and Future Work}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Conclusions}{24}{section.6.1}\protected@file@percent }
\newlabel{sec:ConclusionsConclusions}{{6.1}{24}{Conclusions}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Future work}{24}{section.6.2}\protected@file@percent }
\newlabel{sec:ConclustionsFuturework}{{6.2}{24}{Future work}{section.6.2}{}}
\bibstyle{IEEEtran}
\bibdata{my_reference}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Abbreviations}{25}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:abbreviations}{{7}{25}{Abbreviations}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {.1}Codebase and results}{25}{section.Alph0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Bibliography}{25}{section*.25}\protected@file@percent }
\bibcite{fig:neuron_model}{1}
\bibcite{fig:sigmoid}{2}
\bibcite{fig:neural_network_model}{3}
\bibcite{fig:mnist}{4}
\bibcite{fig:mnist_incorrect}{5}
\bibcite{neural-network-intro}{6}
\bibcite{neural-network-history}{7}
\bibcite{neural-network-intro-book}{8}
\bibcite{nielsen}{9}
\bibcite{towards-data-science}{10}
\bibcite{underfitting-machine-learning}{11}
\bibcite{model-complexity}{12}
\bibcite{backprop-time-complexity}{13}
\bibcite{research-1}{14}
\bibcite{research-2}{15}
\bibcite{research-3}{16}
\bibcite{molchanov2019taylor}{17}
\bibcite{8119196}{18}
\bibcite{7093194}{19}
\bibcite{stochastic-numbers}{20}
\bibcite{stochastic-computing-systems}{21}
\bibcite{stochastic-cnn}{22}
\bibcite{tensorflow}{23}
\bibcite{lecun-website}{24}
\bibcite{lecun-98}{25}
